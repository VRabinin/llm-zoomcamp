{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Getting the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vrabinin/Documents/Github/llm-zoomcamp/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"I just discovered the course. Can I still join it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07822261\n"
     ]
    }
   ],
   "source": [
    "question_vector = embedding_model.encode(user_question)\n",
    "print(question_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()\n",
    "filtered_documents = [doc for doc in documents if doc.get(\"course\") == 'machine-learning-zoomcamp']\n",
    "len(filtered_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Creating the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "embedded_documents = []\n",
    "for doc in filtered_documents:\n",
    "    # Transforming the title into an embedding using the model\n",
    "    qa_text = f'{doc[\"question\"]} {doc[\"text\"]}'\n",
    "    doc[\"qa_embedding\"] = embedding_model.encode(qa_text).tolist()\n",
    "    embeddings.append(doc[\"qa_embedding\"])\n",
    "    embedded_documents.append(doc)\n",
    "    len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 768)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(embeddings)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506574349566924"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = X.dot(question_vector)\n",
    "max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=filtered_documents, embeddings=X)\n",
    "search_results = search_engine.search(question_vector, num_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. Hit-rate for our search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vrabinin/Documents/Github/llm-zoomcamp/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/vrabinin/Documents/Github/llm-zoomcamp/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/vrabinin/Documents/Github/llm-zoomcamp/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'raw.githubusercontent.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "response = requests.get(ground_truth_url, verify=False)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Use StringIO to convert the text content into a file-like object\n",
    "    data = StringIO(response.text)\n",
    "    # Read the data into a DataFrame\n",
    "    df_ground_truth = pd.read_csv(data)\n",
    "    df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "    ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "else:\n",
    "    print(f\"Failed to download data: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate: 93.98907103825137%\n"
     ]
    }
   ],
   "source": [
    "def calculate_hit_rate(search_engine, ground_truth):\n",
    "    num_correct = 0\n",
    "    for query in ground_truth:\n",
    "        question = query['question']\n",
    "        question_vector = embedding_model.encode(question)\n",
    "        course = query['course']\n",
    "        document = query['document']\n",
    "        \n",
    "        search_results = search_engine.search(question_vector, num_results=5)\n",
    "        search_documents = [result['id'] for result in search_results]\n",
    "        \n",
    "        if document in search_documents:\n",
    "            num_correct += 1\n",
    "    \n",
    "    hit_rate = num_correct / len(ground_truth) * 100\n",
    "    return hit_rate\n",
    "\n",
    "hit_rate = calculate_hit_rate(search_engine, ground_truth)\n",
    "print(f\"Hit rate: {hit_rate}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. Indexing with Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '8103cfe6d707', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'olIyrvUQQ2iXypy8GDxUkg', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"id\": {\"type\": \"text\"},  \n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} ,\n",
    "            \"qa_embedding\":{\"type\":\"dense_vector\",\"dims\": 768,\"index\":True,\"similarity\": \"cosine\"\n",
    "        },\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions-hw3'})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"course-questions-hw3\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:01<00:00, 315.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "for doc in tqdm.tqdm(embedded_documents):\n",
    "    try:\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_query = {\n",
    "    \"field\" : \"qa_embedding\",\n",
    "    \"query_vector\" :  question_vector,\n",
    "    \"k\" : 5,\n",
    "    \"num_candidates\" : 10000, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9H1DppAB4hePCQnrC7lF'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = es_client.search(index=index_name, knn=es_query,source=[\"text\",\"section\",\"question\",\"course\"])\n",
    "res[\"hits\"][\"hits\"][0][\"_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Hit-rate for Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate: 94.09836065573771%\n"
     ]
    }
   ],
   "source": [
    "def calculate_es_hit_rate(es_client, index_name,  ground_truth):\n",
    "    num_correct = 0\n",
    "    for query in ground_truth:\n",
    "        question = query['question']\n",
    "        question_vector = embedding_model.encode(question)\n",
    "        course = query['course']\n",
    "        document = query['document']\n",
    "        \n",
    "        es_query = {\n",
    "            \"field\" : \"qa_embedding\",\n",
    "            \"query_vector\" :  question_vector,\n",
    "            \"k\" : 5,\n",
    "            \"num_candidates\" : 10000, \n",
    "        }\n",
    "\n",
    "        search_results = es_client.search(index=index_name, knn=es_query,source=[\"text\",\"id\",\"section\",\"question\",\"course\"])\n",
    "        search_documents = [result['_source']['id'] for result in search_results[\"hits\"][\"hits\"]]\n",
    "        \n",
    "        if document in search_documents:\n",
    "            num_correct += 1\n",
    "    \n",
    "    hit_rate = num_correct / len(ground_truth) * 100\n",
    "    return hit_rate\n",
    "\n",
    "hit_rate = calculate_es_hit_rate(es_client, index_name, ground_truth)\n",
    "print(f\"Hit rate: {hit_rate}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
